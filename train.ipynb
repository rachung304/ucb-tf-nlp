{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['./training_data/yelp_labelled.txt', './training_data/imdb_labelled.txt', './training_data/amazon_cells_labelled.txt']\n",
    "with open('./training_data/training.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./training_data/training.txt\"\n",
    "with open(filename, \"r\", encoding='utf-8') as infile, open('./training_data/positiveReviews.txt','w') as pf, open('./training_data/negativeReviews.txt','w') as nf:\n",
    "    for line in infile:\n",
    "        data = line.rsplit(None,1)\n",
    "        class_label = int(data[-1])\n",
    "        review = data[0]\n",
    "        if class_label == 1:\n",
    "#             print(review)\n",
    "            pf.write(str(review)+\"\\n\")\n",
    "        else:\n",
    "            nf.write(str(review)+\"\\n\")\n",
    "#             print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n",
      "Loaded the word vectors!\n"
     ]
    }
   ],
   "source": [
    "# 6B tokens, 400K vocab, uncased, 50d, 100d, 200d, & 300d vectors\n",
    "wordsList = np.load('./training_data/wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load('./training_data/wordVectors.npy')\n",
    "print ('Loaded the word vectors!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "(400000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(len(wordsList))\n",
    "print(wordVectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Reviews counted\n",
      "Negative Reviews counted\n",
      "Total number of reviews:  3000\n",
      "Total number of words:  35495\n",
      "Average of words in reviews:  11.831666666666667\n"
     ]
    }
   ],
   "source": [
    "positiveReviews = ['./training_data/positiveReviews.txt']\n",
    "negativeReviews = ['./training_data/negativeReviews.txt']\n",
    "\n",
    "wordCount = []\n",
    "for pr in positiveReviews:\n",
    "    with open(pr, \"r\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            counter = len(line.split())\n",
    "#             print(counter)\n",
    "            wordCount.append(counter)\n",
    "print('Positive Reviews counted')\n",
    "\n",
    "for nr in negativeReviews:\n",
    "    with open(nr, \"r\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            counter = len(line.split())\n",
    "            wordCount.append(counter)\n",
    "print('Negative Reviews counted')\n",
    "\n",
    "numReviews = len(wordCount)\n",
    "print('Total number of reviews: ', numReviews)\n",
    "print('Total number of words: ', sum(wordCount))\n",
    "print('Average of words in reviews: ', sum(wordCount)/numReviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1815a53b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(wordCount, 30)\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Occurence')\n",
    "plt.axis([0, 80, 0, 600])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxReviewLength = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(pr) as f:\n",
    "#     sampleSentence = f.readlines()\n",
    "#     print(sampleSentence[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes unnecessary punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wow loved this place\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([14397,  4146,    37,   241,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstSentence = np.zeros((maxReviewLength), dtype='int32')\n",
    "with open(pr) as f:\n",
    "    indexCounter = 0\n",
    "    lines=f.readlines()\n",
    "#     print(lines[125])\n",
    "    cleanedLine = cleanSentences(lines[0])\n",
    "    print(cleanedLine)\n",
    "    split = cleanedLine.split()\n",
    "    for word in split:\n",
    "        if indexCounter < maxReviewLength:\n",
    "            try:\n",
    "                firstSentence[indexCounter] = wordsList.index(word)\n",
    "            except ValueError:\n",
    "                firstSentence[indexCounter] = 399999 #Vector for unknown words\n",
    "        indexCounter = indexCounter + 1\n",
    "firstSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.zeros((numReviews, maxReviewLength), dtype='int32')\n",
    "reviewCounter = 0\n",
    "\n",
    "for pr in positiveReviews:\n",
    "    with open(pr, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            i = 0\n",
    "            cleanedLine = cleanSentences(line)\n",
    "#             print(cleanedLine)\n",
    "            split = cleanedLine.split()\n",
    "            for word in split:\n",
    "#                 print(i)\n",
    "                try:\n",
    "                    ids[reviewCounter][i] = wordsList.index(word)\n",
    "                except ValueError:\n",
    "                    ids[reviewCounter][i] = 399999\n",
    "                i += 1\n",
    "                if i >= maxReviewLength:\n",
    "                    break\n",
    "            reviewCounter += 1\n",
    "            \n",
    "for nr in negativeReviews:\n",
    "    with open(nr, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            i = 0\n",
    "            cleanedLine = cleanSentences(line)\n",
    "            split = cleanedLine.split()\n",
    "            for word in split:\n",
    "#                 print(reviewCounter, i)\n",
    "                try:\n",
    "                    ids[reviewCounter][i] = wordsList.index(word)\n",
    "                except ValueError:\n",
    "                    ids[reviewCounter][i] = 399999\n",
    "                i += 1\n",
    "                if i >= maxReviewLength:\n",
    "                    break\n",
    "            reviewCounter += 1\n",
    "            \n",
    "np.save('idsMatrix', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14397   4146     37 ...      0      0      0]\n",
      " [  1821     21    105 ...      0      0      0]\n",
      " [201534   3692     13 ...      0      0      0]\n",
      " ...\n",
      " [  6779    260     36 ...      0      0      0]\n",
      " [201534     91    873 ...      0      0      0]\n",
      " [    81     86     36 ...      0      0      0]]\n",
      "(3000, 25)\n"
     ]
    }
   ],
   "source": [
    "print(ids)\n",
    "print(ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for splitting Train/Test batch\n",
    "\n",
    "from random import randint\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxReviewLength])\n",
    "    for i in range(batchSize):\n",
    "        if (i % 2 == 0): \n",
    "            num = randint(1,1350)\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            num = randint(1650,3000)\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxReviewLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1350,1650)\n",
    "        if (num <= 1500):\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 20\n",
    "lstmUnits = 16\n",
    "numClasses = 2\n",
    "iterations = 100001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope('input_placeholders'):\n",
    "    labels = tf.placeholder(tf.float32, [batchSize, numClasses], name=\"sentiment_labels\")\n",
    "    input_data = tf.placeholder(tf.int32, [batchSize, maxReviewLength], name=\"input_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numDimensions = 300\n",
    "\n",
    "with tf.name_scope('word_embedding_array'):\n",
    "    data = tf.Variable(tf.zeros([batchSize, maxReviewLength, numDimensions]),dtype=tf.float32, name=\"3D_array\")\n",
    "    data = tf.nn.embedding_lookup(wordVectors,input_data, name=\"Integerizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('LSTM_Params'):\n",
    "    lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "    lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "    value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('LSTM_NN'):\n",
    "    weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]), name=\"weight\")\n",
    "    bias = tf.Variable(tf.constant(0.1, shape=[numClasses]), name=\"bias\")\n",
    "    value = tf.transpose(value, [1, 0, 2], name=\"transposed_output\")\n",
    "    last = tf.gather(value, int(value.get_shape()[0]) - 1, name=\"last\")\n",
    "    prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Prediction'):\n",
    "    correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1), name=\"correct_prediction\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-de49b5321fd0>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('Optimizers'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels), name=\"Mean_Loss\")\n",
    "    optimizer = tf.train.AdamOptimizer(name=\"adam_optimizer\").minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.summary.scalar('Loss', loss)\n",
    "    tf.summary.scalar('Accuracy', accuracy)\n",
    "    merged = tf.summary.merge_all()\n",
    "    logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "    writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to models/pretrained_lstm.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(iterations):\n",
    "    # Next Batch of reviews \n",
    "    nextBatch, nextBatchLabels = getTrainBatch()\n",
    "    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "   #Write summary to Tensorboard\n",
    "    if (i % 50 == 0):\n",
    "        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "   #Save the network every 10,000 training iterations\n",
    "    if (i % 10000 == 0 and i != 0):\n",
    "        save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "        print(\"saved to %s\" % save_path)\n",
    "        \n",
    "sess.graph.as_graph_def()\n",
    "file_writer = tf.summary.FileWriter(\"./graphLSTM\", sess.graph)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/pretrained_lstm.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 1 : 85.00000238418579\n",
      "Accuracy for fold 2 : 85.00000238418579\n",
      "Accuracy for fold 3 : 69.9999988079071\n",
      "Accuracy for fold 4 : 80.0000011920929\n",
      "Accuracy for fold 5 : 85.00000238418579\n",
      "Accuracy for fold 6 : 69.9999988079071\n",
      "Accuracy for fold 7 : 85.00000238418579\n",
      "Accuracy for fold 8 : 85.00000238418579\n",
      "Accuracy for fold 9 : 69.9999988079071\n",
      "Accuracy for fold 10 : 64.99999761581421\n",
      "10 Fold Cross Validation Average Accuracy:  78.50000023841858\n",
      "10 Fold Cross Validation Average Loss:  44.033766090869904\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "kFoldAvgAcc = []\n",
    "kFoldAvgLoss = []\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch()\n",
    "    kFoldAvgAcc.append((sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)\n",
    "    kFoldAvgLoss.append((sess.run(loss, {input_data: nextBatch, labels: nextBatchLabels})) * 100)\n",
    "    print(\"Accuracy for fold\", i+1, \":\" , (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)\n",
    "\n",
    "print(iterations, \"Fold Cross Validation Average Accuracy: \", sum(kFoldAvgAcc) / float(len(kFoldAvgAcc)))\n",
    "# don't know why the loss is so low. \n",
    "print(iterations, \"Fold Cross Validation Average Loss: \", sum(kFoldAvgLoss) / float(len(kFoldAvgLoss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

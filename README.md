# UC Berkeley Tensorflow NLP Project

### Students: Paul Orona, Raymond Chung

## Dependencies:
TensorFlow,
Matplotlib.pyplot,
numpy,
Tensorboard,
Python 3.x,

## Instructions:

Run the train.ipynb

Running the script will return the input texts split into positive and negative review files, and the accuracy from training the model.

Input files are placed in ./training_data

The iterations are set to 100,000 and usual wait time is around 20-30 mins.
The checkpoints will be saved for later on the test runs.

To interactively test the trained model, run train.ipynb and it will ask you for inputs


#### Reference:

http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/

https://github.com/adeshpande3/LSTM-Sentiment-Analysis

https://gist.github.com/vgpena/b1c088f3c8b8c2c65dd8edbe0eae7023

https://github.com/nfmcclure/tensorflow_cookbook

https://github.com/lukas/ml-class/tree/master/tensorflow

https://github.com/dennybritz/cnn-text-classification-tf

https://nlp.stanford.edu/projects/glove/
